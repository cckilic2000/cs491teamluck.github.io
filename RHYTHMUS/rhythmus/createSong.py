import numpy
import glob
import pickle
from keras.models import Sequential
from keras.layers import Dense , Dropout , LSTM , BatchNormalization , Activation
from music21 import note as music21note
from music21 import instrument as inst
from music21 import chord
from music21 import stream
from music21 import converter as conv

def createSong(songName , songLength , generateSongName , userID):
    # Initializing the necessary variables
    seqLength = 100
    rawNotes = []
    xData = []
    dropoutRate = 0.3
    modelSize = 512

    # Getting command line arguments
    chosenSongName = str(songName)
    predictionLength = int(songLength)

    # Loading the backupNotes generated by train.py
    with open('static/savedNotes/backupNotes', 'rb') as path:
        rawNotes = pickle.load(path)

    # Sorted set of notes
    notesSet = sorted(set(rawNotes))

    # Number of distinct notes
    numberOfDistinctNotes = len(notesSet)

    # Length of all notes
    notesLength = len(rawNotes)

    # Dictionaries for conversion between numerical nad alphabetical notes
    integerToNote = {}
    for number, note in enumerate(notesSet):
        integerToNote[number] = note

    noteToInteger = {}
    for number, note in enumerate(notesSet):
        noteToInteger[note] = number

    # Extracting input sequences for the model construction
    for i in range(0 , notesLength - seqLength , 1):
        xData.append([noteToInteger[item] for item in rawNotes[i:i + seqLength]])

    # Reshaping to an acceptable format
    xData = numpy.reshape(xData , (len(xData), seqLength, 1))

    # Normalization of the data
    xData = xData / float(numberOfDistinctNotes)

    # Data shape variables
    shapeVar1 = xData.shape[1]
    shapeVar2 = xData.shape[2]

    # Model spesifications
    model = Sequential()
    model.add(LSTM(modelSize , recurrent_dropout = dropoutRate , return_sequences = True , input_shape=(shapeVar1 , shapeVar2)))
    model.add(LSTM(modelSize , recurrent_dropout = dropoutRate , return_sequences = True))
    model.add(LSTM(modelSize))
    model.add(BatchNormalization())
    model.add(Dropout(dropoutRate))
    model.add(Dense(modelSize / 2))
    model.add(Activation('relu'))
    model.add(BatchNormalization())
    model.add(Dropout(dropoutRate))
    model.add(Dense(numberOfDistinctNotes))
    model.add(Activation('softmax'))
    model.compile(loss='categorical_crossentropy', optimizer = 'rmsprop')

    model.load_weights('static/weights.hdf5')

    # Variable for chosen song notes
    chosenSongNotes = []

    # Getting the notes of the chosen song
    for item in glob.glob("static/trainMusics/" + str(chosenSongName)):
        midiFile = conv.parse(item)

        tempNotes = None

        # Try to get only piano notes except take flat notes
        try:
            notesByInst = inst.partitionByInstrument(midiFile)
            # instrumentNotes.parts[0] stores piano notes
            tempNotes = notesByInst.parts[0].recurse() 
        except:
            tempNotes = midiFile.flat.notes

        # Reformat notes and chords
        for element in tempNotes:
            if isinstance(element , chord.Chord):
                tempString = []
                for chordNote in element.normalOrder:
                    tempString.append(str(chordNote))
                chosenSongNotes.append('.'.join(tempString))
            elif isinstance(element , music21note.Note):
                noteVar = str(element.pitch)
                chosenSongNotes.append(noteVar)

    # Shaping the chosen song
    chosenSongXData = []
    chosenSongLength = len(chosenSongNotes)

    for i in range(0 , chosenSongLength - seqLength , 1):
        chosenSongXData.append([noteToInteger[item] for item in chosenSongNotes[i:i + seqLength]])

    # Random index point
    chosenSongXDataLength = len(chosenSongXData)
    randIndex = numpy.random.randint(0 , chosenSongXDataLength - 1)

    # Starting data and output list
    predictedNotes = []
    predictionData = chosenSongXData[randIndex]

    # Predict notes
    for i in range(predictionLength):
        # Normalizing and reshaping data
        predictionX = numpy.reshape(predictionData , (1 , seqLength , 1))
        predictionX = predictionX / float(numberOfDistinctNotes)

        # Make the prediction
        modelOutput = model.predict(predictionX)

        # Reshape the predicted note and add to predictedNotes
        noteVal = integerToNote[numpy.argmax(modelOutput)]
        predictedNotes.append(noteVal)

        # Update the input list
        predictionData.append(numpy.argmax(modelOutput))
        predictionData = predictionData[1:(seqLength + 1)]

    offSet = 0
    midiNotes = []

    for predictedNote in predictedNotes:
        if ('.' in predictedNote) or predictedNote.isdigit():
            splitNotes = predictedNote.split('.')
            tempNotes = []
            for splitNote in splitNotes:
                tempNote = music21note.Note(int(splitNote))
                tempNote.storedInstrument = inst.Piano()
                tempNotes.append(tempNote)
            tempChord = chord.Chord(tempNotes)
            tempChord.offset = offSet
            midiNotes.append(tempChord)
        else:
            tempNote = music21note.Note(predictedNote)
            tempNote.offset = offSet
            tempNote.storedInstrument = inst.Piano()
            midiNotes.append(tempNote)

        offSet = offSet + 0.5

    midiStream = stream.Stream(midiNotes)
    midiStream.write('midi', fp='static/usersongs/' + str(generateSongName)+ '_' + str(userID) + '.mid')